---
layout: post
title: "正则表达式效率分析"
description: ""
category: 
tags: [正则表达式]
---
{% include JB/setup %}

### 两种引擎 ###


要分析正则表达式效率的问题首先需要了解正则表达式引擎运行的原理。简单的说，正则表达式的引擎主要有两种：
* DFA Deterministic finite automaton 确定型有穷自动机
* NFA Non-deterministic finite automaton 非确定型有穷自动机

DFA又称为文本导向的引擎，比如用正则

        abc|abcdef
去匹配字符串"abcdefghi",匹配的结果是abcdef。它的过程是这样子的：拿字符串中的地一个字符"a"跟正则的两个分支匹配，匹配成功。然后把权限让给第二个字符"b"，"b"跟两个分支匹配也成功，然后第三个字符"c"，"c"匹配成功之后匹配的过程没有结束。而是继续用后面的字符"d"去跟正则匹配，这时候第一个分支匹配失败，被淘汰掉，第二个分支匹配成功。后续"e""f"也匹配成功，所以最后的结果是匹配成功，匹配到的字符串是"abcdef".

NFA又称为正则导向的引擎。还是用上一个例子。如果是一个正则导向的引擎去匹配的话，匹配到的结果是"abc",而不是"abcdef"。它的工作过程是这样子的，一开始的控制权是在正则表达式的手里。它用"abc|abcdef"的地一个分支去跟要匹配的字符串"abcdefghi"，（在之前DFA的工作流程中，控制权是在字符串手里，用字符串去跟正则匹配，所以DFA成为文本导向。这里，控制权在正则表达式的手里，所以称为正则导向）正则第一个分支"abc"跟字符串"abcdefghi"匹配成功之后，NFA引擎就立刻上报发现成功匹配，匹配结果是"abc"，它就不会继续去匹配正则的第二个分支了。

示例：
egrep 默认使用的正则引擎是DFA，grep -P 参数是指用perl的正则引擎，属于NFA的引擎。可以看到匹配到的字符是不同的。

![test]({{site.img_url}}egrep.png)
### DFA与NFA的区别 ###

DFA不需要回溯，匹配快速，但是不支持捕获组，所以也不支持反向引用等多种特性。目前使用DFA引擎的语言和工具主要有awk，egrep和lex。

NFA支持捕获组，惰性量词等，需要回溯。所以他的匹配速度相对慢一些，但是支持的特性多。我们平时用的大多数语言和工具都是NFA引擎。比如:java,php,python,ruby.....

本文对于正则表达式效率的讨论也是基于标准的NFA引擎。

### 性能和回溯###

正则的语法就不介绍了。这里用一个例子稍微详细的介绍一下正则匹配的过程和回溯的概念。用正则

	ID:\s*(.*?)MMM
去匹配

	ID:   S-1-2MMM
 先看一下匹配过程。

![backtrack]({{site.img_url}}backtrack.png)

先用正则的I跟字符串的I匹配，匹配成功，后面类似。当控制权权到

	\s*
这里的时候，\s和修饰它的量词是作为一个整体来匹配的。由于是贪婪模式，所以第四步，一下匹配了3个空格。然后控制权到了

	(.*?)
这里是非贪婪模式，所以它优先选任意字符出现零次，即什么都没有匹配。（这里是第5,第6步，因为有括号。所以是两步）只是在这里做了一个标记，因为这里有多种可能行，当后面匹配失败，就会重新回到这里，然后控制权就到了正则里的

	M
这里。第七步，M跟字符串的S匹配，匹配失败。控制权重新回到

	(.*?)
这里。这个过程就是一个回溯。回到这里之后，这次就会去尝试匹配一个任意字符。这里匹配了S，然后在这里做了标记，控制权又交给了M，M匹配又失败，又回溯到之前标记的地方。

可以看到这个成功的匹配过程经过了5次回溯。下图是匹配失败时候的回溯，其实匹配成功一般不会有性能问题，出现性能问题一般都是匹配失败的时候。

为了方便讲解，把正则跟需要匹配的字符串都简化了一下：

	正则：ID:\s*(.*?)M
	字符串：ID: SN
匹配失败，用了30步。

![shibai]({{site.img_url}}jianhua2.png)

匹配成功的时候只有10步。

![chenggong]({{site.img_url}}jianhua.png)


其实最好的办法是放到regexbuddy里调试一下。可以看到16步，当后面的都匹配失败，回溯点回到了

	\s* 这里。\s*是贪婪匹配，之前匹配了一个空格。
可是后面的都匹配失败了，它至少吐一个空格出来。然后，后面的

	(.*?)M再来一边。
17步是

	(.*?) 非贪婪匹配，匹配了零个字符。。。。。。

### 如何避免回溯 ###


回溯可能产生的地方有两个，一个是分支结构，一个是量词。

对于分支结构来说，可以把概率高的分支放在前面，因为NFA是优先选择左端的结果。

对于量词来说有两个思路。

  *  一个是元字符的精确化，就是尽量详细分析字符内容，慎重用点号星号。
  *  另一个就是用原子组和占有优先量词避免回溯。

#### 实例测试 ####

	(已成功登录帐户。\s*主题:\s*安全 ID:\s*(.*?)\s*帐户名:\s*(.*?)\s*帐户域:\s*(.*?)\s*登录 ID:\s*(.*?)\s*登录类型:\s*(.*?)\s* 新登录:\s*安全 ID\s*(.*?)\s*帐户名:\s*(.*?)\s*帐户域:\s*(.*?)\s*登录 ID:\s*(.*?)\s*登录 GUID:\s*(.*?)\s*进程信息:\s*进程 ID:\s*(.*?)\s*进程名:\s*(.*?)\s*网络信息:\s*工作站名:\s*(.*?)\s*源网络地址:\s*(?:\-|(\S+))\s*源端口:\s*(?:(\d+)|\-)\s*详细身份验证信息:\s*登录进程:\s*(.*?)\s*身份验证数据包:\s*(.*?)\s*传递服务:\s*(.*?)\s*数据包名\(仅限 NTLM\):\s*(.*?)\s*密钥长度:\s*(.*?)\s*在创建登录会话后在被访问的计算机上生成此事件。\s*“主题”字段指明本地系统上请求登录的帐户。\s*这通常是一个服务\(例如 Server 服务\)或本地进程\(例如 Winlogon.exe 或 Services.exe\)。\s*“登录类型”字段指明发生的登录种类。\s*最常见的类型是 2 \(交互式\)和 3 \(网络\)。\s*“新登录”字段会指明新登录是为哪个帐户创建的，即登录的帐户。\s*“网络”字段指明远程登录请求来自哪里。\s*“工作站名”并非总是可用，而且在某些情况下可能会留为空白。\s*“身份验证信息”字段提供关于此特定登录请求的详细信息。\s*-“登录 GUID”是可以用于将此事件与一个 KDC 事件关联起来的唯一标识符。\s*-“传递服务”指明哪些直接服务参与了此登录请求。\s*- “数据包名”指明在 NTLM 协议之间使用了哪些子协议。\s*-“密钥长度”指明生成的会话密钥的长度。\s*如果没有请求会话密钥则此字段为 0。)

这个例子中直接测试的话regexbuddy匹配超过100万次就停止了（下面的次数都是指匹配失败的情况下）。实际匹配完成需要的次数可能远远超过100万次。如果把

	(.*?) 全部换成 (\S*?)
之后只需要2300次左右匹配就结束了。当然这里账户名可能含有空格，如果把账户名，账户域，依然用点星来匹配，其他的换成\S,需要的匹配次数仍然超过100万次。看起来这个问题主要是由于点号导致的。可以再进一步优化下，把点号换成

	[^:]
既假设用户名里是不含有冒号的。这样子的匹配次数是依然超过100万次。。。貌似没有什么效果。

上面的方法都是基于字符精确话这个原则。此外还可以利用原子组和占有优先量词避免回溯。以占有优先量词为例，它的语法是在量词后面加一个+号。

	比如： \s*+  这样子的话，它匹配到的字符会作为一个整体，不会再产生回溯。
虽然上面的正则是贪婪匹配，匹配到了好几个空格，但是加了占有优先量词，就不会再出现吐一个字符出来，产生回溯的情况。

这个例子中，经过上面的优化没有效果的情况下，把每个冒号后面的第一个

	\s* 换成 \s*+
匹配次数降到了3万次，已经可以运行了。其实这个效果并不是很好。当把登录ID的

	\S*? 换成 .*?之后，匹配次数马上达到了27万次

#### 真的是点号的问题么 ####

经过一番调试发现，如果把

	\s*(.*?)\s* 换成(.*?)
匹配次数只需要38000次，所以把量词修饰的元字符放在一起才是造成这个性能问题的主要原因。前面提到的避免回溯的原则也应该加一条：相邻的元字符尽量不要都用星号加号量词修饰，量词的嵌套也应该谨慎。

这里\s其实是用来净化捕获组的获取的字符串。不知道我们现在程序是怎样处理的。去掉首尾的空格。
